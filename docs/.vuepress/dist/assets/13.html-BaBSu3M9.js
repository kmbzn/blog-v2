import{_ as e,c as l,a,o as t}from"./app-CFlH2mst.js";const n="/assets/image-51-DqGOLU_I.png",s="/assets/image-52-BlFfhZox.png",r={};function o(u,i){return t(),l("div",null,[...i[0]||(i[0]=[a('<h1 id="_13-intro-to-qa-testing" tabindex="-1"><a class="header-anchor" href="#_13-intro-to-qa-testing"><span>13. Intro to QA Testing</span></a></h1><h2 id="learning-goals" tabindex="-1"><a class="header-anchor" href="#learning-goals"><span>Learning Goals</span></a></h2><ul><li>Testing을 (비구조적) 차원에서 coverage를 달성하기 위한 활동으로 간주</li><li>Usability, reliability, security, robustness (일반 및 아키텍처), performance, integration과 같은 품질 속성 평가를 위한 testing 전략 열거</li><li>Trade-off를 제시하고 각 technique이 유용할 수 있는 시점 식별</li><li>Testing을 프로젝트의 lifecycle 및 practice에 통합</li><li>Test plan 개요 작성</li></ul><h2 id="quality-assurance-qa-is-hard" tabindex="-1"><a class="header-anchor" href="#quality-assurance-qa-is-hard"><span>Quality Assurance (QA) is <strong>HARD</strong></span></a></h2><ul><li>QA &amp; Software Testing은 MS에서 도전적인 과제</li><li>Microsoft와 같은 대형 상용 소프트웨어 회사에서는 development만큼 testing 수행</li><li>Developer만큼 많은 tester 보유. Tester는 항상 testing 수행, developer는 약 절반의 시간을 testing 과정에 참여</li><li>Test case는 매우 비쌈. 프로그램 자체보다 test harness에 더 많은 code 라인 존재 (종종 약 3:1 비율)</li><li>Time Estimates (in hours):</li></ul><table><thead><tr><th>Activity</th><th>Estimated</th><th>Actual</th></tr></thead><tbody><tr><td>Testing plans</td><td>3</td><td>0</td></tr><tr><td>Unit testing</td><td>3</td><td>1</td></tr><tr><td>Validation testing</td><td>4</td><td>2</td></tr><tr><td>Test data</td><td>1</td><td>1</td></tr></tbody></table><p><img src="'+n+'" alt="alt text"></p><h2 id="qa-has-many-facets" tabindex="-1"><a class="header-anchor" href="#qa-has-many-facets"><span>QA has Many Facets</span></a></h2><ul><li>Questions</li><li>Specification이 올바른지 어떻게 보장하는가?</li><li>시스템이 specification을 충족하는지 어떻게 보장하는가?</li><li>시스템이 사용자의 요구를 충족하는지 어떻게 보장하는가?</li><li>시스템이 잘못 동작하지 않는지 어떻게 보장하는가?</li></ul><h2 id="verification-vs-validation" tabindex="-1"><a class="header-anchor" href="#verification-vs-validation"><span>Verification vs Validation</span></a></h2><ul><li>Verification: 시스템이 specification을 충족하는가? <ul><li>즉, 시스템을 올바르게 구축했는가?</li></ul></li><li>Verification: Design 또는 code에 결함이 있는가? <ul><li>즉, 잘못된 design 또는 implementation 결정이 있는가?</li></ul></li><li>Validation: 시스템이 사용자의 요구를 충족하는가? <ul><li>즉, 올바른 시스템을 구축했는가?</li></ul></li><li>Validation: Specification에 결함이 있는가? <ul><li>즉, requirements 캡처를 잘못 수행했는가?</li></ul></li></ul><h2 id="brief-case-discussion" tabindex="-1"><a class="header-anchor" href="#brief-case-discussion"><span>Brief Case Discussion</span></a></h2><p><img src="'+s+'" alt="alt text"></p><blockquote><p><em>어떤 qualities가 중요하며, 어떻게 그것을 보장할 수 있을까?</em></p></blockquote><h2 id="very-important" tabindex="-1"><a class="header-anchor" href="#very-important"><span>Very Important</span></a></h2><ul><li>모든 품질 문제를 완벽하게 해결할 수 있는 단일 analysis technique은 없음</li><li>어떤 technique이 적절한지는 여러 요인에 따라 다름 <ul><li>해당 시스템 (및 크기/복잡성), 품질 목표, 가용 resource, 안전/보안 요구사항 등</li></ul></li></ul><h2 id="definition-software-analysis" tabindex="-1"><a class="header-anchor" href="#definition-software-analysis"><span>Definition: Software Analysis</span></a></h2><blockquote><p>Software artifact의 속성을 결정하기 위한 체계적인 조사</p></blockquote><ul><li>포괄적이 되려는 시도 <ul><li>예: Test coverage, inspection check list, exhaustive model checking</li></ul></li><li>자동: Regression testing, static analysis, dynamic analysis</li><li>수동: Manual testing, inspection, modeling</li><li>Code, system, module, execution trace, test case, design 또는 requirements 문서</li></ul><h2 id="principle-techniques" tabindex="-1"><a class="header-anchor" href="#principle-techniques"><span>Principle Techniques</span></a></h2><ul><li>Dynamic: <ul><li>Testing: 통제된 환경에서 test data로 code를 직접 실행</li><li>Analysis: Test run에서 data를 추출하는 tool</li></ul></li><li>Static: <ul><li>Inspection: Code, design 문서 (spec 및 model), 수정 사항에 대한 인간의 평가</li><li>Analysis: Tool이 program을 실행하지 않고 reasoning</li></ul></li></ul><h2 id="no-single-technique" tabindex="-1"><a class="header-anchor" href="#no-single-technique"><span>No Single Technique</span></a></h2><ul><li>모든 품질 문제를 완벽하게 해결할 수 있는 단일 analysis technique은 없음</li><li>어떤 technique이 적절한지는 여러 요인에 따라 다름 <ul><li>해당 시스템 (및 크기/복잡성), 품질 목표, 가용 resource, 안전/보안 요구사항 등</li></ul></li></ul><h2 id="what-is-testing" tabindex="-1"><a class="header-anchor" href="#what-is-testing"><span>What is Testing?</span></a></h2><ul><li>통제된 환경에서 test data로 code를 직접 실행</li><li>주요 목표: <ul><li>Verification: Program이 품질 속성을 포함한 requirements를 충족하는지 확인</li><li>Defect testing: Failure 발견</li></ul></li><li>기타 목표: <ul><li>Reveal bugs (주요 목표)</li><li>Assess quality (정량화 어려움)</li><li>Clarify the specification, documentation</li><li>Verify contracts</li></ul></li><li>&quot;Testing shows the presence, not the absence of bugs.” -Edsger W. Dijkstra 1969</li></ul><h2 id="software-errors" tabindex="-1"><a class="header-anchor" href="#software-errors"><span>Software Errors</span></a></h2><ul><li>Functional errors</li><li>Performance errors</li><li>Deadlock</li><li>Race conditions</li><li>Boundary errors</li><li>Buffer overflow</li><li>Integration errors</li><li>Usability errors</li><li>Robustness errors</li><li>Load errors</li><li>Design defects</li><li>Versioning and configuration errors</li><li>Hardware errors</li><li>State management errors</li><li>Metadata errors</li><li>Error-handling errors</li><li>User interface errors</li><li>API usage errors</li><li>…</li></ul><h2 id="what-are-we-covering" tabindex="-1"><a class="header-anchor" href="#what-are-we-covering"><span>What are We Covering?</span></a></h2><ul><li>Program/system 기능: <ul><li>Execution space (white box!)</li><li>Input 또는 requirements space (black box!)</li></ul></li><li>예상되는 사용자 경험 (usability) <ul><li>GUI testing, A/B testing</li></ul></li><li>예상되는 performance envelope (performance, reliability, robustness, integration) <ul><li>Security, robustness, fuzz, infrastructure testing</li><li>Performance 및 reliability: soak 및 stress testing</li><li>Integration 및 reliability: API/protocol testing</li></ul></li></ul><h2 id="traditional-coverage" tabindex="-1"><a class="header-anchor" href="#traditional-coverage"><span>“Traditional” Coverage</span></a></h2><ul><li>Statement</li><li>Branch</li><li>Function</li><li>Path (?)</li><li>MC/DC</li></ul><h2 id="we-can-measure-coverage-on-almost-anything" tabindex="-1"><a class="header-anchor" href="#we-can-measure-coverage-on-almost-anything"><span>We Can Measure Coverage on Almost Anything</span></a></h2><ul><li>Testing을 위한 일반적인 adequacy criteria는 program execution 또는 specification space의 전체 &quot;coverage&quot;에 근접</li><li>주어진 verification 활동이 목표를 달성한 정도를 측정. 활동의 adequacy 근사</li><li>가장 자주 testing에 적용되지만, 모든 verification 활동에 적용 가능</li><li>측정된 항목 중 적어도 한 번 실행되거나 평가된 항목의 총 수에 대한 비율로 표현. 보통 백분율로 표현</li></ul><h2 id="testing-levels" tabindex="-1"><a class="header-anchor" href="#testing-levels"><span>Testing Levels</span></a></h2><ul><li>Unit testing</li><li>Integration testing</li><li>System testing</li></ul><h2 id="junit" tabindex="-1"><a class="header-anchor" href="#junit"><span>JUnit</span></a></h2><ul><li>Java를 위한 인기 있는 unit-testing framework</li><li>사용하기 쉬움</li><li>Tool 지원 가능</li><li>Design mechanism으로 사용 가능</li></ul><h2 id="test-driven-development" tabindex="-1"><a class="header-anchor" href="#test-driven-development"><span>Test Driven Development</span></a></h2><ul><li>Test 우선!</li><li>인기 있는 agile technique</li><li>Code 작성 전 specification으로 test 작성</li><li>실패하는 test 없이 code 작성 금지</li><li>주장: <ul><li>Testable design을 향한 design 접근 방식</li><li>Interface 우선 고려</li><li>불필요한 code 작성 방지</li><li>더 높은 제품 품질 (예: 더 나은 code, 더 적은 defect)</li><li>더 높은 test suite 품질</li><li>더 높은 전반적인 생산성</li></ul></li></ul><h2 id="continuous-integration" tabindex="-1"><a class="header-anchor" href="#continuous-integration"><span>Continuous Integration</span></a></h2><ul><li>자동으로 build, test 및 결과 표시</li></ul><h2 id="regression-testing" tabindex="-1"><a class="header-anchor" href="#regression-testing"><span>Regression Testing</span></a></h2><ul><li>일반적인 model: <ul><li>Bug fix 등을 위해 regression test 도입</li><li>Code가 evolve함에 따라 결과 비교</li></ul></li><li>Code1 + TestSet -&gt; TestResults1</li><li>Code2 + TestSet -&gt; TestResults2</li><li>Code가 evolve함에 따라 TestResults1을 TestResults2 등과 비교</li><li>Specification이 변경되지 않는 한 동일해야 함</li><li>이점: <ul><li>Bug fix가 유지되고 bug가 다시 나타나지 않도록 보장</li><li>Specification에 대한 의존도 감소</li></ul></li></ul><h1 id="the-oracle-problem" tabindex="-1"><a class="header-anchor" href="#the-oracle-problem"><span>The Oracle Problem</span></a></h1><h2 id="what-are-we-covering-1" tabindex="-1"><a class="header-anchor" href="#what-are-we-covering-1"><span>What are We Covering?</span></a></h2><ul><li>Program/system 기능: <ul><li>Execution space (white box!)</li><li>Input 또는 requirements space (black box!)</li></ul></li><li>예상되는 사용자 경험 (usability) <ul><li>GUI testing, A/B testing</li></ul></li><li>예상되는 performance envelope (performance, reliability, robustness, integration) <ul><li>Security, robustness, fuzz, infrastructure testing</li><li>Performance 및 reliability: soak 및 stress testing</li><li>Integration 및 reliability: API/protocol testing</li></ul></li></ul><h2 id="usability-testing" tabindex="-1"><a class="header-anchor" href="#usability-testing"><span>Usability Testing</span></a></h2><ul><li>Specification?</li><li>Test harness? Environment?</li><li>Nondeterminism?</li><li>Unit testing?</li><li>Automation?</li><li>Coverage?</li></ul><h2 id="automating-gui-web-testing" tabindex="-1"><a class="header-anchor" href="#automating-gui-web-testing"><span>Automating GUI/Web Testing</span></a></h2><ul><li>어려움</li><li>Capture and Replay Strategy <ul><li>Mouse actions</li><li>System events</li></ul></li><li>Test Scripts: (&quot;Start&quot; 버튼 클릭, Y 필드에 값 X 예상)</li><li>많은 tool 및 framework <ul><li>예: JUnit + Jemmy (Java/Swing)</li><li>Selenium (Web)</li></ul></li><li>(Model을 GUI와 분리하여 GUI testing 부하 방지)</li><li>Functional correctness를 넘어서?</li></ul><h2 id="manual-testing" tabindex="-1"><a class="header-anchor" href="#manual-testing"><span>Manual Testing?</span></a></h2><ul><li>Live System?</li><li>Extra Testing System?</li><li>Check output / assertions?</li><li>Effort, Costs?</li><li>Reproducible?</li></ul><h2 id="usability-a-b-testing" tabindex="-1"><a class="header-anchor" href="#usability-a-b-testing"><span>Usability: A/B Testing</span></a></h2><ul><li>Control (A)과 treatment (B)인 두 가지 variant를 이용한 통제된 무작위 experiment</li><li>한 사용자 그룹에는 A (현재 시스템) 제공, 다른 무작위 그룹에는 B 제시. 결과 비교</li><li>Web 또는 GUI 기반 application에서 자주 사용됨 (특히 광고 또는 GUI 요소 배치/design 결정 test)</li></ul><h1 id="example" tabindex="-1"><a class="header-anchor" href="#example"><span>Example</span></a></h1><h2 id="what-are-we-covering-2" tabindex="-1"><a class="header-anchor" href="#what-are-we-covering-2"><span>What are We Covering?</span></a></h2><ul><li>Program/system 기능: <ul><li>Execution space (white box!)</li><li>Input 또는 requirements space (black box!)</li></ul></li><li>예상되는 사용자 경험 (usability) <ul><li>GUI testing, A/B testing</li></ul></li><li>예상되는 performance envelope (performance, reliability, robustness, integration) <ul><li>Security, robustness, fuzz, infrastructure testing</li><li>Performance 및 reliability: soak 및 stress testing</li><li>Integration 및 reliability: API/protocol testing</li></ul></li></ul><h2 id="security-robustness-testing" tabindex="-1"><a class="header-anchor" href="#security-robustness-testing"><span>Security/Robustness Testing</span></a></h2><ul><li>Specification?</li><li>Test harness? Environment?</li><li>Nondeterminism?</li><li>Unit testing?</li><li>Automation?</li><li>Coverage?</li></ul><h2 id="random-testing" tabindex="-1"><a class="header-anchor" href="#random-testing"><span>Random Testing</span></a></h2><ul><li>Program의 input domain에서 무작위로 input 독립적 선택 <ul><li>Program의 input domain 식별</li><li>난수를 해당 input domain에 mapping</li><li>특정 확률 분포에 따라 input domain에서 input 선택</li><li>해당 input에 대해 program이 적절한 output을 달성하는지 확인</li></ul></li><li>Random testing은 program의 faultiness에 대한 확률적 보장 제공</li><li>예: Failure 없이 약 23,000개 input (N = 23,000)을 사용한 random testing은 90% 신뢰도 (C = 0.9)로 program이 10,000번 중 1번 (F = 104) 이상 failure하지 않음을 입증</li></ul><h2 id="reliability-fuzz-testing" tabindex="-1"><a class="header-anchor" href="#reliability-fuzz-testing"><span>Reliability: Fuzz Testing</span></a></h2><ul><li>Program, device 또는 system에 malformed (비정상) 및 unexpected input data를 feed하여 security 관련 defect 또는 denial of service, degradation of service 또는 기타 원치 않는 behavior로 이어지는 critical flaw를 찾는 negative software testing 방법 (A. Takanen et al, 2008)</li><li>Fuzz test를 생성하거나 fuzz testing을 수행하는 데 사용되는 program 및 framework를 fuzzer라고 함</li></ul><h2 id="types-of-faulty-found" tabindex="-1"><a class="header-anchor" href="#types-of-faulty-found"><span>Types of Faulty Found</span></a></h2><ul><li>Pointer/array errors</li><li>Not checking return codes</li><li>Invalid/out of boundary data</li><li>Data corruption</li><li>Signed characters</li><li>Race conditions</li><li>Undocumented features</li><li>...Possible tradeoffs?</li></ul><h2 id="fuzzing-process" tabindex="-1"><a class="header-anchor" href="#fuzzing-process"><span>Fuzzing Process</span></a></h2><ul><li>Seed pool</li><li>모든 seed input i1에 대해</li></ul><ol><li>선택:</li></ol><ul><li>선호되는 input 우선</li></ul><ol start="2"><li>수정:</li></ol><ul><li>Bitflip</li><li>Byteflip</li><li>...</li><li>(Modified seed input)</li><li>(One cycle)</li></ul><ol start="3"><li>새 path를 cover하지 않는 input 버리기</li><li>새 path를 cover하는 input을 pool에 추가</li></ol><h2 id="unit-and-regression-testing-for-performance" tabindex="-1"><a class="header-anchor" href="#unit-and-regression-testing-for-performance"><span>Unit and Regression Testing for Performance</span></a></h2><ul><li>Critical component의 execution time 측정</li><li>Execution time을 log로 기록하고 시간에 따라 비교</li></ul><h2 id="profiling" tabindex="-1"><a class="header-anchor" href="#profiling"><span>Profiling</span></a></h2><ul><li>Execution time 및 memory 병목 현상 찾기</li></ul><h2 id="performance-testing-during-design" tabindex="-1"><a class="header-anchor" href="#performance-testing-during-design"><span>Performance Testing During Design</span></a></h2><ul><li>Modeling 및 simulation <ul><li>예: queuing theory</li></ul></li></ul><h2 id="stress-testing" tabindex="-1"><a class="header-anchor" href="#stress-testing"><span>Stress Testing</span></a></h2><ul><li>Robustness testing technique: 정상 작동 한계를 넘어 test</li><li>System granularity의 모든 level에서 적용 가능</li><li>Stress test는 일반적으로 heavy load 하에서의 robustness, availability, error handling에 중점</li></ul><h2 id="soak-testing" tabindex="-1"><a class="header-anchor" href="#soak-testing"><span>Soak Testing</span></a></h2><ul><li>문제: System이 인위적으로 제한된 execution 조건 하에서는 예상대로 작동할 수 있음 <ul><li>예: Memory leak은 failure로 이어지는 데 더 오래 걸릴 수 있음</li></ul></li><li>Soak testing: 상당한 load 하에 상당한 time 동안 system을 testing (긍정)</li><li>주어진 duration과 threshold 하에서 simulated 환경의 test 대상 반응 확인에 사용</li></ul><h1 id="chaos-engineering" tabindex="-1"><a class="header-anchor" href="#chaos-engineering"><span>Chaos Engineering</span></a></h1><h2 id="chaos-monkey" tabindex="-1"><a class="header-anchor" href="#chaos-monkey"><span>Chaos Monkey</span></a></h2><ul><li>Netflix infrastructure testing system</li><li>&quot;악의적인&quot; program이 component, network, datacenter, AWS instance 등을 무작위로 손상</li><li>Chaos monkey가 최초 – production instance를 무작위로 비활성화</li><li>다른 monkey로는 Latency Monkey, Doctor Monkey, Conformity Monkey 등이 있음. Infrastructure level에서의 Fuzz testing</li><li>System architecture가 계획되지 않은/무작위 outage에 resilient한지 확인하기 위해 component의 failure 강제</li><li>Netflix는 chaos monkey code를 open-source로 공개</li></ul><h1 id="brief-case-discussion-1" tabindex="-1"><a class="header-anchor" href="#brief-case-discussion-1"><span>Brief Case Discussion</span></a></h1><h2 id="what-are-we-covering-3" tabindex="-1"><a class="header-anchor" href="#what-are-we-covering-3"><span>What are We Covering?</span></a></h2><ul><li>Program/system 기능: <ul><li>Execution space (white box!)</li><li>Input 또는 requirements space (black box!)</li></ul></li><li>예상되는 사용자 경험 (usability) <ul><li>GUI testing, A/B testing</li></ul></li><li>예상되는 performance envelope (performance, reliability, robustness, integration) <ul><li>Security, robustness, fuzz, infrastructure testing</li><li>Performance 및 reliability: soak 및 stress testing</li><li>Integration 및 reliability: API/protocol testing</li></ul></li></ul><h2 id="completeness" tabindex="-1"><a class="header-anchor" href="#completeness"><span>Completeness?</span></a></h2><ul><li>통계적 threshold <ul><li>보고된/수리된 defect</li><li>Defect 종류의 상대적 비율</li><li>&quot;Going gold&quot; 예측 변수</li></ul></li><li>Coverage criterion <ul><li>예: 항공 software에 100% coverage 필요</li><li>Software 왜곡</li><li>Matrix: Test case를 requirements use case에 mapping</li></ul></li><li>과거 data 참조 가능 <ul><li>조직 내에서 project 간 비교 가능. 기대치 및 예측 변수 개발</li><li>조직 간에는 commensurability의 어려움으로 인해 더 어려움 (예: 항공 software vs. 소비자 software)</li></ul></li><li>경험 법칙: Error detection rate가 떨어질 때 (testing investment 대비 diminishing returns 의미)</li><li>가장 일반적: Time 또는 money 소진</li></ul><h2 id="limits-of-testing" tabindex="-1"><a class="header-anchor" href="#limits-of-testing"><span>Limits of Testing</span></a></h2><ul><li>실행되지 않은 code의 bug를 찾을 수 없으며, bug 부재 보장 불가</li><li>Oracle problem</li><li>Nondeterminism, flaky tests <ul><li>특정 종류의 bug는 매우 드문 조건에서만 발생</li></ul></li><li>Specification 관찰/단언 어려움 <ul><li>Memory leaks, information flow, …</li></ul></li><li>잠재적으로 비싸고 긴 실행 time</li><li>잠재적으로 높은 manual effort</li><li>Verification, not validation</li><li>...</li></ul>',92)])])}const h=e(r,[["render",o]]),d=JSON.parse('{"path":"/se/13.html","title":"13. Intro to QA Testing","lang":"ko-KR","frontmatter":{},"git":{"updatedTime":1764305376000,"contributors":[{"name":"kmbzn","username":"kmbzn","email":"kmbzn24@gmail.com","commits":3,"url":"https://github.com/kmbzn"}],"changelog":[{"hash":"f81f9042e7888855a506f92261c74aaa2d86aa2a","time":1764305376000,"email":"kmbzn24@gmail.com","author":"kmbzn","message":"update npm"},{"hash":"58c6bc5240203e74ef2e574994ccb1e6a1bf5568","time":1763157653000,"email":"kmbzn24@gmail.com","author":"kmbzn","message":"Refactor code structure for improved readability and maintainability"},{"hash":"6120a63360466143831636b40c0f1ff3226d9d3e","time":1763149723000,"email":"kmbzn24@gmail.com","author":"kmbzn","message":"Refactor code structure for improved readability and maintainability"}]},"filePathRelative":"se/13.md"}');export{h as comp,d as data};
