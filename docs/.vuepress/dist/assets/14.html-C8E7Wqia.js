import{_ as i,c as s,a as l,o as a}from"./app-DYuS003L.js";const t="/assets/image-68-BM8F5fdI.png",r="/assets/image-67-uAve-Isp.png",n="/assets/image-64-B4f8joZl.png",o="/assets/image-65-IBIFfXsw.png",c="/assets/image-66-DH8ITSP0.png",u={};function d(h,e){return a(),s("div",null,[...e[0]||(e[0]=[l('<h1 id="_14-qa-process" tabindex="-1"><a class="header-anchor" href="#_14-qa-process"><span>14. QA Process</span></a></h1><h2 id="quality-assurance-process" tabindex="-1"><a class="header-anchor" href="#quality-assurance-process"><span>Quality Assurance Process</span></a></h2><ul><li>How to get developers to <ul><li>write tests</li><li>use static analysis</li><li>appreciate testers</li></ul></li></ul><h2 id="learning-goals" tabindex="-1"><a class="header-anchor" href="#learning-goals"><span>Learning Goals</span></a></h2><ul><li>QA의 Process 측면 이해</li><li>QA 기술들의 Tradeoffs 설명</li><li>주어진 프로젝트와 Quality attribute에 적합한 QA 기술 선택</li><li>QA의 시점(When)과 분량(How much) 결정</li><li>Process 내에서 QA 기술을 강제하는 방법에 대한 개념 개요</li><li>Tools와 Policies를 Process에 통합하는 시점과 방법 선택: Daily builds, Continuous integration, Test automation, Static analysis, Issue tracking 등</li><li>QA 기술 도입 시의 인간적 및 사회적 과제(Human and social challenges) 이해</li><li>Process와 Tool 개선이 기능(Features)과 품질(Quality) 사이의 딜레마를 어떻게 해결할 수 있는지 이해</li></ul><h2 id="qa-process-considerations" tabindex="-1"><a class="header-anchor" href="#qa-process-considerations"><span>QA Process Considerations</span></a></h2><ul><li>우리는 몇 가지 QA 기술을 (간략히) 다루었음 <ul><li>Formal verification</li><li>Unit testing, Test driven development</li><li>Quality attributes를 위한 다양한 형태의 Advanced testing (GUI testing, Fuzz testing 등)</li><li>Static analysis</li><li>Dynamic analysis</li><li>Formal inspections 및 다른 형태의 Code reviews</li></ul></li><li>그러나: 언제 사용할 것인가? 어떤 기술을? 얼마나? 어떻게 도입할 것인가? Quality culture를 어떻게 확립할 것인가? 규정 준수(Compliance)를 어떻게 보장할 것인가? Social issues는? 외부 Components는 어떻게 할 것인가?</li></ul><h2 id="case-study-google-s-tricorder" tabindex="-1"><a class="header-anchor" href="#case-study-google-s-tricorder"><span>Case Study: Google’s Tricorder</span></a></h2><h2 id="integrate-static-analysis-in-review-process" tabindex="-1"><a class="header-anchor" href="#integrate-static-analysis-in-review-process"><span>Integrate Static Analysis in Review Process</span></a></h2><ul><li>Code review 도구 내의 Bots으로서의 Static analysis <ul><li>각 Commit마다 자동으로 적용됨</li><li>결과가 Author와 Reviewers에게 보임</li></ul></li><li>가벼운 Checkers, 추가 및 수정이 용이함</li><li>효과적이지 않은 Checkers를 표시하기 위한 Feedback buttons 제공</li></ul><h2 id="tricorder" tabindex="-1"><a class="header-anchor" href="#tricorder"><span>Tricorder</span></a></h2><ul><li>Sadowski, Caitlin, et al. &quot;Tricorder: Building a program analysis ecosystem.&quot; 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering. Vol. 1. IEEE, 2015.</li></ul><h2 id="case-study-qa-previously-at-microsoft" tabindex="-1"><a class="header-anchor" href="#case-study-qa-previously-at-microsoft"><span>Case Study: QA (previously) at Microsoft</span></a></h2><h2 id="how-does-microsoft-work" tabindex="-1"><a class="header-anchor" href="#how-does-microsoft-work"><span>How does Microsoft Work?</span></a></h2><h2 id="microsoft-s-culture" tabindex="-1"><a class="header-anchor" href="#microsoft-s-culture"><span>Microsoft&#39;s Culture</span></a></h2><ul><li>최고의 Developers 채용 <ul><li>&quot;IBM이 수천 명이 필요한 일을 Microsoft는 수백 명의 일류 Developers로 달성할 수 있음&quot;</li></ul></li><li>그들에게 자유 부여</li><li>제품별 Teams가 크게 독립적임</li><li>비교적 짧은 Development cycles <ul><li>Version updates (예: Excel 3-&gt;4) 1-2개월</li><li>New products 1-4년</li><li>Release date에 의해 주도됨</li></ul></li><li>사전 Specification이 거의 없으며, 변경 및 기능 축소(Cutting features)에 유연함</li></ul><h2 id="early-days-1984-separate-testing-from-development" tabindex="-1"><a class="header-anchor" href="#early-days-1984-separate-testing-from-development"><span>Early Days (1984): Separate Testing from Development</span></a></h2><ul><li>Hardware manufacturers로부터의 Bug 불만 제기 후 (예: BASIC의 잘못된 계산)</li><li>Customers가 제품에 대해 불만 제기</li><li>IBM은 Microsoft가 개발 및 품질 관리(Quality control) Process를 개선할 것을 주장</li><li>심각한 데이터 파괴 Bug로 인해 Microsoft는 20,000명의 사용자에게 각각 $10의 비용을 들여 Multiplan 업데이트를 배송해야 했음</li><li>Developers와 일부 Management(Balmer 포함)의 저항: &quot;Developers가 스스로 자신의 제품을 테스트할 수 있으며, 가끔 고등학생, 비서, 외부 계약직의 도움을 받으면 됨&quot;</li><li>외부 Testers 고용</li><li>Formal inspections의 관료주의, 단계 간 Signoff, 또는 시간 기록(Time logging)을 회피</li><li>별도의 Testing group; Automated tests; 신규 입사자 및 Critical components에 대한 Code reviews</li></ul><h2 id="early-days-1986-testing-groups" tabindex="-1"><a class="header-anchor" href="#early-days-1986-testing-groups"><span>Early Days (1986): Testing Groups</span></a></h2><ul><li>&quot;Developers가 게을러짐&quot;, QA를 Test team에 의존</li><li>&quot;Infinite defects&quot; - Developers가 수정하는 속도보다 Testers가 Defects를 더 빨리 찾아냄</li><li>늦고 거대한 Integrations (&quot;Big bang&quot;) - 긴 Testing periods, 출시 지연</li><li>Mac Word 3 재앙: 8개월 지연, 수백 개의 Bugs (Crashing 및 데이터 파괴 Bugs 포함); 무료 업그레이드에 100만 달러 소요</li><li>품질 전달(Delivering quality)에 대한 압박 증가</li></ul><h2 id="_1989-retreat-and-zero-defects" tabindex="-1"><a class="header-anchor" href="#_1989-retreat-and-zero-defects"><span>1989 Retreat and “Zero defects”</span></a></h2><p><img src="'+t+'" alt="alt text"></p><h2 id="zero-defect-rules-for-excel-4" tabindex="-1"><a class="header-anchor" href="#zero-defect-rules-for-excel-4"><span>Zero-Defect Rules for Excel 4</span></a></h2><ul><li>모든 변경 사항은 Compile 및 Link 되어야 함</li><li>모든 변경 사항은 Mac 및 Windows에서 Automated quick tests를 통과해야 함</li><li>할당된 Open bugs가 10개를 초과하는 Developer는 새로운 기능을 진행하기 전에 이를 수정해야 함</li></ul><h2 id="testing-buddies" tabindex="-1"><a class="header-anchor" href="#testing-buddies"><span>Testing Buddies</span></a></h2><ul><li>Development와 Test teams가 분리되어 있으며, 대략 비슷한 규모</li><li>Developers는 자신의 코드를 테스트하고 Automated tests를 매일 실행</li><li>개별 Testers가 종종 한 명의 Developer에게 배정됨 <ul><li>그들의 Private releases (Branch)를 테스트하고, 코드가 Merge 되기 전에 이메일로 직접적이고 신속한 Feedback 제공</li></ul></li></ul><h2 id="testers" tabindex="-1"><a class="header-anchor" href="#testers"><span>Testers</span></a></h2><ul><li>Support team 및 Customers와 소통하고, 미디어 평가를 검토하도록 장려됨</li><li>High-risk 영역에 대한 Testing strategy 개발</li><li>다양한 형태의 Testing 수행 (내부적으로 불리는 명칭): Unstructured testing, Ad hoc testing, Gorilla testing, Free-form Fridays</li></ul><h2 id="early-mid-90s" tabindex="-1"><a class="header-anchor" href="#early-mid-90s"><span>Early-mid 90s</span></a></h2><ul><li>Zero defect 목표 (1989 memo)</li><li>Milestones (1988년 Publisher 1.0에서 처음 도입)</li><li>Version control, Branches, 빈번한 Integration</li><li>Daily builds</li><li>Automated tests (&quot;Quick autotest&quot;) - Checkin 전에 반드시 성공해야 함</li><li>Usability labs</li><li>Beta testing (Win 95의 경우 400,000명의 Beta testers), Instrumentation 포함</li><li>간략한 Formal design reviews; 선별된 Code reviews</li><li>Defect tracking 및 Metrics</li><li>Developers가 한 Release cycle 이상 Product group에 머무름</li></ul><h2 id="metrics" tabindex="-1"><a class="header-anchor" href="#metrics"><span>Metrics</span></a></h2><ul><li>Severity(심각도) 별 Open bugs 수 <ul><li>Open bugs 수는 Milestone 전에 감소할 것으로 예상됨</li><li>알려진 모든 심각한 Bugs는 Release 전에 수정되어야 함</li><li>Severity 1 (Product crash), Severity 2 (Feature crash), Severity 3 (Bug with workaround), Severity 4 (Cosmetic/Minor)</li><li>Releases 및 Projects 전반에 걸쳐 Metrics 추적</li></ul></li><li>Performance metrics</li><li>Bug data는 &quot;출시 준비 완료(Ready to ship)&quot; 결정에 사용됨 <ul><li>절대적인 관점이 아닌 상대적이고 실용적인 관점</li><li>&quot;시장은 늦는 것은 용서하지만, 버그가 많은 것은 용서하지 않을 것이다&quot;</li></ul></li></ul><h2 id="challenges-of-microsoft-s-culture" tabindex="-1"><a class="header-anchor" href="#challenges-of-microsoft-s-culture"><span>Challenges of Microsoft’s Culture</span></a></h2><ul><li>Product teams 간의 소통이 거의 없음</li><li>Developers와 Testers가 종종 &quot;Software engineering 문헌을 잘 읽지 않아, 바퀴를 재발명(Reinventing the wheel)함&quot; <ul><li>Architecture, Design, Components 공유, Quality metrics 등을 오랫동안 과소평가함</li></ul></li><li>Developers가 변화와 &quot;관료주의(Bureaucracy)&quot;에 저항함</li></ul><h2 id="project-postmortem" tabindex="-1"><a class="header-anchor" href="#project-postmortem"><span>Project Postmortem</span></a></h2><ul><li>체계적인 문제점과 모범 사례 식별 (10-150 페이지 보고서) <ul><li>반복되는 문제와 잘 작동하는 관행 문서화</li><li>예 <ul><li>Breadth-first → Depth-first &amp; Tested milestones</li><li>불충분한 Specification</li><li>Commits를 리뷰하지 않음</li><li>가정(Assumptions)을 전달하기 위해 Asserts 사용</li><li>적절한 Tools 부족 → Automated tests</li><li>Testers와 Beta releases를 위한 Instrumented versions</li><li>Zero defect rule이 Developers의 우선순위가 아님</li></ul></li></ul></li><li>메모(Memos)로 통찰력을 순환시키고, Team 간 학습 장려</li></ul><h2 id="process-audits" tabindex="-1"><a class="header-anchor" href="#process-audits"><span>Process Audits</span></a></h2><ul><li>문제가 있는 Projects에 대한 비공식적인 1주 Audits</li><li>Metrics 분석, Team members 인터뷰</li><li>다른 Teams의 Best practices를 채택하도록 권고 <ul><li>Daily builds, Automated tests, Milestones, Reviews</li></ul></li></ul><h2 id="the-2002-trustworthy-computing-memo" tabindex="-1"><a class="header-anchor" href="#the-2002-trustworthy-computing-memo"><span>The 2002 Trustworthy Computing Memo</span></a></h2><ul><li>Microsoft가 고객의 신뢰를 확보하고 유지하기 위해 회사 차원에서 해야 할 많은 변화들이 있음 - Software 개발 방식부터 지원 노력, 운영 및 비즈니스 관행에 이르기까지</li><li>Software가 더욱 복잡해지고, 상호 의존적이며 상호 연결됨에 따라, 회사로서의 평판 또한 더 취약해졌음</li><li>단일 Microsoft 제품, 서비스 또는 정책의 결함(Flaws)은 Platform 및 Services 전반의 품질뿐만 아니라, 회사에 대한 고객의 시각에도 영향을 미침</li></ul><h2 id="code-reviews" tabindex="-1"><a class="header-anchor" href="#code-reviews"><span>Code Reviews</span></a></h2><ul><li>자체 Code review 도구 보유 (Passaround style)</li><li>Reviews가 얼마나 효과적인지에 대한 내부 연구</li><li>Code reviews를 개선하기 위한 내부 Tools</li></ul><h2 id="slam-sdv-since-2000" tabindex="-1"><a class="header-anchor" href="#slam-sdv-since-2000"><span>SLAM/SDV (since 2000)</span></a></h2><ul><li>목표: 종종 Drivers에 의해 발생하는 Blue screens 감소</li><li>C 언어용 Driver verification tool</li><li>Model checking 기술</li><li>좁은 범위의 Protocol 위반(Violations) 클래스 발견 <ul><li>Drivers의 특성 사용 (일반 C 코드가 아님)</li><li>Microsoft의 잘 테스트된 샘플 Drivers에서 여러 Bugs 발견</li></ul></li><li>Microsoft compiler suite에서 완전히 자동화됨</li><li>무료로 이용 가능</li><li>Driver certification program을 통해 강제됨</li><li>강력한 비즈니스 사례: 대부분의 Blue screens 제거</li><li>Model checking의 기초 과학에 기반: 공공 자금 지원을 받은 대학 연구실에서 유래</li></ul><h2 id="_2010-agile" tabindex="-1"><a class="header-anchor" href="#_2010-agile"><span>2010: Agile</span></a></h2><ul><li>Web-based services 및 C++ 진화는 더 빠른 Iteration 요구</li><li>Agile 방법론 수용</li><li>Testing team의 대규모 축소 (Developer 당 2명의 Testers에서 1명 미만으로): 이제 Developers가 자신의 Testing을 수행할 것으로 기대됨</li></ul><h2 id="annotation" tabindex="-1"><a class="header-anchor" href="#annotation"><span>Annotation</span></a></h2><ul><li>수백만 줄의 Unannotated code가 있는 상황에서 Developers에게 어떻게 동기를 부여할 것인가?</li><li>Microsoft의 접근 방식 <ul><li>Checkin 시 Annotations 요구 (예: __ecount()가 없는 char*가 포함된 코드 거부)</li><li>어차피 주석(Comment)에 넣을 내용처럼 Annotations를 자연스럽게 만듦</li></ul></li><li>이제 기계가 확인 가능(Machine checkable)</li><li>Engineering practices와 맞지 않는 Formality 회피 <ul><li>점진성(Incrementality)</li></ul></li><li>모든 Compile 마다 Code design consistency 확인</li><li>노력의 각 증가분(Increment)에 대해 프로그래머에게 보상 <ul><li>부분적인 Code에 Annotations를 달아도 이점 제공</li><li>Code의 가장 중요한 부분에 먼저 집중 가능</li><li>핑계 방지: 마감일 이후에 하겠다</li></ul></li><li>Annotations를 추론(Infer)하는 Tools 구축 <ul><li>Inference는 근사적이어서 Annotations 변경이 필요할 수 있지만, 전반적인 작업 절약</li><li>불행히도 Microsoft 외부에서는 아직 사용 불가</li></ul></li></ul><h2 id="sage" tabindex="-1"><a class="header-anchor" href="#sage"><span>SAGE</span></a></h2><ul><li>White-box fuzz testing (Symbolic-execution 기반 Test generation)</li><li>특히 File 및 Protocol parsing routines의 Security issues 대상 <ul><li>&quot;Image processors, Media players, File decoders, Document parsers를 포함한 수백 개의 Microsoft applications에서 이전에 알려지지 않은 많은 Security vulnerabilities 발견&quot;</li></ul></li><li>자체 SMT constraint solver (Z3)</li><li>Research project에서 Large-scale deployment로 발전 <ul><li>200대의 머신에서 대규모 실행</li></ul></li></ul><h2 id="bug-prediction" tabindex="-1"><a class="header-anchor" href="#bug-prediction"><span>Bug Prediction</span></a></h2><ul><li>Metrics</li><li>Software repositories 마이닝(Mining)</li><li>결과 예시 <ul><li>Distributed development는 중요하지 않지만, Organizational distance는 중요함</li></ul></li><li>현재 Testing effort 우선순위 지정에 활용 중</li></ul><h2 id="boogie-dafny" tabindex="-1"><a class="header-anchor" href="#boogie-dafny"><span>Boogie, Dafny, ...</span></a></h2><ul><li>Intermediate Verification Language</li><li>&quot;사용 가능한 Formal verification&quot; <ul><li>Dafny 언어...</li></ul></li><li>현재 활발히 연구 중...</li></ul><h2 id="case-study-microsoft" tabindex="-1"><a class="header-anchor" href="#case-study-microsoft"><span>Case Study: Microsoft</span></a></h2><ul><li>Microsoft는 Features 단위로 Software 계획</li><li>Release 당 3-4개의 Milestones</li><li>각 Milestone 이후, 어떤 Features를 여전히 구현해야 할지 재고</li><li>Milestone 말에 Stabilization 및 Freeze</li></ul><h2 id="prepare-servicing-strategy-for-windows-10-updates" tabindex="-1"><a class="header-anchor" href="#prepare-servicing-strategy-for-windows-10-updates"><span>Prepare Servicing Strategy for Windows 10 Updates</span></a></h2><p><img src="'+r+'" alt="alt text"></p><h2 id="qa-process-considerations-1" tabindex="-1"><a class="header-anchor" href="#qa-process-considerations-1"><span>QA Process Considerations</span></a></h2><ul><li>우리는 몇 가지 QA 기술을 (간략히) 다루었음 <ul><li>Formal verification</li><li>Unit testing, Test driven development</li><li>Quality attributes를 위한 다양한 형태의 Advanced testing (GUI testing, Fuzz testing 등)</li><li>Static analysis</li><li>Dynamic analysis</li><li>Formal inspections 및 다른 형태의 Code reviews</li></ul></li><li>그러나: 언제 사용할 것인가? 어떤 기술을? 얼마나? 어떻게 도입할 것인가? Quality culture를 어떻게 확립할 것인가? 규정 준수(Compliance)를 어떻게 보장할 것인가? Social issues는? 외부 Components는 어떻게 할 것인가?</li></ul><h2 id="start-qa-as-soon-as-possible" tabindex="-1"><a class="header-anchor" href="#start-qa-as-soon-as-possible"><span>Start QA As Soon As Possible</span></a></h2><p><img src="'+n+'" alt="alt text"></p><h2 id="qualities-and-risks" tabindex="-1"><a class="header-anchor" href="#qualities-and-risks"><span>Qualities and Risks</span></a></h2><ul><li>어떤 Qualities가 요구되는가? (Requirements engineering)</li><li>어떤 Risks가 예상되는가?</li><li>Qualities와 Risks에 기반하여 QA strategy 조정(Align)</li></ul><h2 id="test-plans-linking-development-and-testing" tabindex="-1"><a class="header-anchor" href="#test-plans-linking-development-and-testing"><span>Test Plans Linking Development and Testing</span></a></h2><p><img src="'+o+'" alt="alt text"></p><h2 id="example-sql-injection-attacks" tabindex="-1"><a class="header-anchor" href="#example-sql-injection-attacks"><span>Example: SQL Injection Attacks</span></a></h2><blockquote><p>어떤 QA strategy가 적합한가? <img src="'+c+'" alt="alt text"></p></blockquote><h2 id="example-scalability" tabindex="-1"><a class="header-anchor" href="#example-scalability"><span>Example: Scalability</span></a></h2><ul><li>어떤 QA strategy가 적합한가?</li></ul><h2 id="example-usability" tabindex="-1"><a class="header-anchor" href="#example-usability"><span>Example: Usability</span></a></h2><ul><li>어떤 QA strategy가 적합한가?</li></ul><h2 id="qa-tradeoffs" tabindex="-1"><a class="header-anchor" href="#qa-tradeoffs"><span>QA Tradeoffs</span></a></h2><ul><li>QA 접근 방식의 한계 이해 <ul><li>예: Testing 대 Static analysis, Formal verification 대 Inspection 등</li></ul></li><li>기술들을 혼합하여 사용(Mix and match)</li><li>다른 Qualities를 위해 다른 기술 사용</li></ul><h1 id="qa-within-the-process" tabindex="-1"><a class="header-anchor" href="#qa-within-the-process"><span>QA within the Process</span></a></h1><h2 id="qa-as-part-of-the-process" tabindex="-1"><a class="header-anchor" href="#qa-as-part-of-the-process"><span>QA as Part of the Process</span></a></h2><ul><li>Milestones에서의 QA 산출물(Deliverables) 보유 (Management policy) <ul><li>Milestone 전 Inspection / Test report</li></ul></li><li>Development practices 변경 (Developer의 동의 필요) <ul><li>예: Continuous integration, Pair programming, Reviewed checkins, Zerobug, Checking 전 Static analysis</li></ul></li><li>Code review의 일부로서의 Static analysis (Google)</li><li>Bugs 및 기타 Quality metrics 추적</li></ul><h2 id="defect-tracking" tabindex="-1"><a class="header-anchor" href="#defect-tracking"><span>Defect Tracking</span></a></h2><ul><li>Issues: Bug, Feature request, Query</li><li>측정(Measurement)의 기초 <ul><li>어떤 Phase에서 보고되었는가</li><li>수리 기간, 난이도</li><li>분류(Categorization)</li><li>→ Root cause analysis</li></ul></li><li>의사소통 촉진(Facilitates communication) <ul><li>보고자에게 다시 질문</li><li>보고서가 잊히지 않도록 보장</li></ul></li><li>책임(Accountability)</li></ul><h2 id="enforcement" tabindex="-1"><a class="header-anchor" href="#enforcement"><span>Enforcement</span></a></h2><ul><li>Microsoft: Check in gates <ul><li>Analysis suite가 실행되어 오류가 생성되지 않아야 Code를 Check in 가능</li><li>Test coverage, Dependency violation, 불충분/나쁜 Design intent, Integer overflow, Allocation arithmetic, Buffer overruns, Memory errors, Security issues</li></ul></li><li>eBay: Dev/QA handoff <ul><li>Developers는 데스크탑에서 FindBugs 실행</li><li>QA는 Code 수신 시 FindBugs 실행, 결과 게시, 높은 우선순위 수정 요구</li></ul></li><li>Google: Commits에 대한 Static analysis, Review에 표시됨</li><li>성공을 위한 요구사항 <ul><li>낮은 False positives</li><li>False positive 경고를 무시(Override)할 수 있는 방법 (일반적으로 Inspection을 통해)</li><li>Developers가 먼저 Static analysis를 받아들여야 함</li></ul></li></ul><h1 id="social-aspects" tabindex="-1"><a class="header-anchor" href="#social-aspects"><span>Social Aspects</span></a></h1><h2 id="social-issues" tabindex="-1"><a class="header-anchor" href="#social-issues"><span>Social Issues</span></a></h2><ul><li>Defects에 대한 Developer의 태도</li><li>Security에 대한 Developer 교육</li><li>QA practices 강제를 위해 동료 압력(Peer pressure) 사용 <ul><li>Breaking the build - 다양한 규칙들</li></ul></li><li>Developer 대 Tester 문화</li><li>Testers는 나쁜 소식을 전하는 경향이 있음</li><li>성과 평가(Performance evaluations)에 Defects 포함?</li><li>Issues 대 Defects</li><li>좋은 Test suits는 신뢰도(Confidence)를 높이고, Shared code ownership 장려</li></ul><h2 id="reporting-defects" tabindex="-1"><a class="header-anchor" href="#reporting-defects"><span>Reporting Defects</span></a></h2><ul><li>재현 가능한(Reproducible) Defects</li><li>간단하고 일반적임(Simple and general)</li><li>보고서 당 하나의 Defect</li><li>적대적이지 않음(Non-antagonistic) <ul><li>(Testers는 보통 나쁜 소식을 가져옴)</li><li>문제(Problem)를 진술</li><li>비난하지 않음(Don&#39;t blame)</li></ul></li></ul><h2 id="reporting-defects-bad" tabindex="-1"><a class="header-anchor" href="#reporting-defects-bad"><span>Reporting Defects (BAD)</span></a></h2><h2 id="reporting-defects-good" tabindex="-1"><a class="header-anchor" href="#reporting-defects-good"><span>Reporting Defects (GOOD)</span></a></h2><h2 id="summary" tabindex="-1"><a class="header-anchor" href="#summary"><span>Summary</span></a></h2><ul><li>QA plan 개발 <ul><li>Quality goals 및 Risks 식별</li><li>접근 방식 혼합 및 매칭(Mix and match)</li><li>QA 강제(Enforce), 관행(Practices) 확립</li></ul></li><li>Microsoft의 Case study</li><li>Process 내 QA 통합</li><li>QA의 Social issues</li></ul>',90)])])}const m=i(u,[["render",d]]),g=JSON.parse('{"path":"/se/14.html","title":"14. QA Process","lang":"ko-KR","frontmatter":{},"git":{"updatedTime":1764309303000,"contributors":[{"name":"kmbzn","username":"kmbzn","email":"kmbzn24@gmail.com","commits":1,"url":"https://github.com/kmbzn"}],"changelog":[{"hash":"4062b1472d26318057ccbc92972d0c6e452aba97","time":1764309303000,"email":"kmbzn24@gmail.com","author":"kmbzn","message":"Refactor code structure for improved readability and maintainability"}]},"filePathRelative":"se/14.md"}');export{m as comp,g as data};
